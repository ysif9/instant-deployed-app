{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":129601,"databundleVersionId":15542776,"sourceType":"competition"},{"sourceId":14715851,"sourceType":"datasetVersion","datasetId":9402216}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# BraTS Improved Submission Pipeline\n\nThis notebook implements key improvements to increase Dice score:\n\n1. **Correct RLE Encoding**: C-order (row-major), 1-indexed\n2. **Proper Orientation**: RAS for inference ‚Üí LPS for submission\n3. **Threshold Optimization**: Per-class thresholds\n4. **Post-processing**: Remove small components, fill holes, enforce hierarchy\n5. **Test-Time Augmentation (TTA)**: Average predictions from flipped volumes\n\nRun all cells in order.","metadata":{}},{"cell_type":"code","source":"# Cell 1: Install dependencies\n!pip install -q monai nibabel scipy scikit-image tqdm pandas numpy torch","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport sys\nimport glob\nimport logging\nimport time\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.cuda.amp import autocast\nimport nibabel as nib\nfrom tqdm.auto import tqdm\nfrom scipy.ndimage import zoom, label as scipy_label, binary_fill_holes, binary_dilation, binary_erosion\nfrom skimage.morphology import remove_small_objects\nfrom dataclasses import dataclass\nfrom typing import Tuple, List, Dict\n\nfrom monai.transforms import (\n    Compose, LoadImaged, EnsureChannelFirstd, ConcatItemsd, DeleteItemsd,\n    Orientationd, Spacingd, NormalizeIntensityd, CropForegroundd, SpatialPadd,\n)\nfrom monai.inferers import SlidingWindowInferer","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def setup_logger(name: str = \"BraTS_Inference\", log_file: str = None) -> logging.Logger:\n    \"\"\"Setup logger that prints to stdout (visible on Kaggle) and optionally to file.\"\"\"\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.INFO)\n    logger.handlers = []  # Clear existing handlers\n    logger.propagate = False  # Prevent duplicate logging with INFO:BraTS prefix\n\n    # Console handler - prints to stdout (visible on Kaggle)\n    console_handler = logging.StreamHandler(sys.stdout)\n    console_handler.setLevel(logging.INFO)\n    console_format = logging.Formatter(\n        '%(asctime)s | %(levelname)s | %(message)s',\n        datefmt='%Y-%m-%d %H:%M:%S'\n    )\n    console_handler.setFormatter(console_format)\n    logger.addHandler(console_handler)\n\n    # File handler (optional)\n    if log_file:\n        file_handler = logging.FileHandler(log_file)\n        file_handler.setLevel(logging.INFO)\n        file_handler.setFormatter(console_format)\n        logger.addHandler(file_handler)\n\n    return logger\n\n\n# Initialize logger\nlogger = setup_logger(\"BraTS_Inference\", \"/kaggle/working/inference.log\")\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nlogger.info(f\"Using device: {device}\")\nsys.stdout.flush()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n@dataclass\nclass Config:\n    # Paths - UPDATE THESE FOR KAGGLE\n    test_dir: str = \"/kaggle/input/instant-odc-ai-hackathon/test\"\n    model_path: str = \"/kaggle/input/best-5-epoch-model/best_model.pth\"\n    output_csv: str = \"/kaggle/working/submission.csv\"\n\n    # Model architecture\n    patch_size: Tuple[int, int, int] = (128, 128, 128)\n    in_channels: int = 4\n    out_channels: int = 3\n\n    # Inference settings\n    sw_batch_size: int = 2\n    overlap: float = 0.6  # Good for boundary consistency\n    use_amp: bool = True\n    target_spacing: Tuple[float, float, float] = (1.0, 1.0, 1.0)\n\n    # BALANCED thresholds (between 0.7137 and 0.6465 runs)\n    threshold_tc: float = 0.52  # Slightly higher than original 0.5\n    threshold_wt: float = 0.47  # Between 0.45 and 0.50\n    threshold_et: float = 0.57  # Between 0.55 and 0.60\n\n    # Post-processing (MODERATE)\n    min_component_size: int = 150  # Between 100 and 200\n    fill_holes: bool = True\n    enforce_hierarchy: bool = True\n    apply_erosion: bool = False  # DISABLED - was too aggressive\n    erosion_iterations: int = 0\n\n    # Test-Time Augmentation\n    use_tta: bool = True\n    tta_flips: List[int] = None\n\n    # Evaluation / Validation (optional - for datasets with ground truth)\n    enable_evaluation: bool = True  # Set to True to calculate Dice scores\n    ground_truth_dir: str = \"/kaggle/input/brain-tumor-segmentation-hackathon\"  # Path to hackathon dataset with labels\n\n\nconfig = Config()\nconfig.tta_flips = [0, 1, 2]\n\nMODALITY_KEYS = [\"flair\", \"t1\", \"t1ce\", \"t2\"]\nORIGINAL_SHAPE = (240, 240, 155)\n\nlogger.info(f\"Config loaded (BALANCED):\")\nlogger.info(f\"  Thresholds: TC={config.threshold_tc}, WT={config.threshold_wt}, ET={config.threshold_et}\")\nlogger.info(f\"  TTA enabled: {config.use_tta}\")\nlogger.info(f\"  Post-processing: min_size={config.min_component_size}, fill_holes={config.fill_holes}\")\nlogger.info(f\"  Erosion: {config.apply_erosion}\")\nlogger.info(f\"  Overlap: {config.overlap}\")\nsys.stdout.flush()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ConvBlock(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super().__init__()\n        self.conv1 = nn.Conv3d(in_ch, out_ch, 3, padding=1, bias=False)\n        self.norm1 = nn.InstanceNorm3d(out_ch, affine=True)\n        self.conv2 = nn.Conv3d(out_ch, out_ch, 3, padding=1, bias=False)\n        self.norm2 = nn.InstanceNorm3d(out_ch, affine=True)\n        self.act = nn.LeakyReLU(0.01, True)\n\n    def forward(self, x):\n        return self.act(self.norm2(self.conv2(self.act(self.norm1(self.conv1(x))))))\n\n\nclass DownBlock(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super().__init__()\n        self.conv = ConvBlock(in_ch, out_ch)\n        self.pool = nn.MaxPool3d(2)\n\n    def forward(self, x):\n        skip = self.conv(x)\n        return self.pool(skip), skip\n\n\nclass UpBlock(nn.Module):\n    def __init__(self, in_ch, skip_ch, out_ch):\n        super().__init__()\n        # Renamed 'up' to 'upsample' to match checkpoint\n        self.upsample = nn.ConvTranspose3d(in_ch, in_ch, 2, stride=2)\n        self.conv = ConvBlock(in_ch + skip_ch, out_ch)\n\n    def forward(self, x, skip):\n        # Use renamed layer\n        x = self.upsample(x)\n        if x.shape != skip.shape:\n            d = [skip.shape[i + 2] - x.shape[i + 2] for i in range(3)]\n            x = F.pad(x, [d[2] // 2, d[2] - d[2] // 2, d[1] // 2, d[1] - d[1] // 2, d[0] // 2, d[0] - d[0] // 2])\n        return self.conv(torch.cat([x, skip], 1))\n\n\nclass UNet3D(nn.Module):\n    def __init__(self):\n        super().__init__()\n        f = [64, 96, 128, 192, 256, 384]\n        self.encoders = nn.ModuleList([DownBlock(4 if i == 0 else f[i - 1], c) for i, c in enumerate(f[:-1])])\n        self.bottleneck = ConvBlock(f[-2], f[-1])\n        self.decoders = nn.ModuleList(\n            [UpBlock(f[-1] if i == 0 else f[-2 - i + 1], f[-2 - i], f[-2 - i]) for i in range(len(f) - 1)])\n        # Renamed 'out' to 'output_head' to match checkpoint\n        self.output_head = nn.Conv3d(f[0], 3, 1)\n\n        # Deep Supervision heads expected by checkpoint (ignored in forward)\n        # We don't necessarily need to define them if we use strict=False,\n        # but defining them prevents \"unexpected key\" messages if we cared.\n        # We will use strict=False.\n\n    def forward(self, x):\n        skips = []\n        for e in self.encoders:\n            x, s = e(x)\n            skips.append(s)\n        x = self.bottleneck(x)\n        for d, s in zip(self.decoders, skips[::-1]):\n            x = d(x, s)\n        # Use renamed layer\n        return self.output_head(x)\n\n\n# Load model\nlogger.info(\"=\" * 70)\nlogger.info(\"MODEL LOADING\")\nlogger.info(\"=\" * 70)\nmodel = UNet3D().to(device)\nif os.path.exists(config.model_path):\n    logger.info(f\"Loading model from {config.model_path}...\")\n    sys.stdout.flush()\n    try:\n        state_dict = torch.load(config.model_path, map_location=device)\n        # Check if state_dict is inside a key (e.g., 'model_state_dict')\n        if 'model_state_dict' in state_dict:\n            state_dict = state_dict['model_state_dict']\n\n        # Use strict=False to ignore ds_head weights (Auxiliary heads)\n        model.load_state_dict(state_dict, strict=False)\n        logger.info(f\"‚úÖ Model loaded successfully (strict=False)\")\n        sys.stdout.flush()\n    except Exception as e:\n        logger.error(f\"‚ùå Failed to load model: {e}\")\n        sys.stdout.flush()\nelse:\n    logger.error(f\"‚ùå Model not found at {config.model_path}\")\n    sys.stdout.flush()\n\nmodel.eval()\nlogger.info(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\nlogger.info(\"=\" * 70)\nsys.stdout.flush()\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def rle_encode_c_order(mask: np.ndarray) -> str:\n    \"\"\"\n    RLE encoding using C-order (row-major), 1-indexed.\n    THIS IS THE CORRECT FORMAT FOR THE COMPETITION!\n\n    Args:\n        mask: 3D binary numpy array (240, 240, 155)\n\n    Returns:\n        RLE string: \"start1 length1 start2 length2 ...\"\n    \"\"\"\n    # CRITICAL: Use C-order (row-major) flattening\n    flat = mask.flatten(order='C')\n\n    if flat.sum() == 0:\n        return \"\"\n\n    # Pad with zeros to detect runs at boundaries\n    flat = np.concatenate([[0], flat, [0]])\n    runs = np.where(flat[1:] != flat[:-1])[0]\n\n    runs = runs.reshape(-1, 2)\n    starts = runs[:, 0] + 1  # Convert to 1-indexed\n    lengths = runs[:, 1] - runs[:, 0]\n\n    rle_pairs = [f\"{s} {l}\" for s, l in zip(starts, lengths)]\n    return \" \".join(rle_pairs)\n\n\ndef rle_decode_c_order(rle_string: str, shape: tuple = (240, 240, 155)) -> np.ndarray:\n    \"\"\"Decode RLE string to 3D mask (C-order, 1-indexed).\"\"\"\n    if not rle_string or rle_string.strip() == '':\n        return np.zeros(shape, dtype=np.uint8)\n\n    mask = np.zeros(np.prod(shape), dtype=np.uint8)\n    rle_pairs = rle_string.strip().split()\n\n    for i in range(0, len(rle_pairs), 2):\n        start = int(rle_pairs[i]) - 1  # Convert to 0-indexed\n        length = int(rle_pairs[i + 1])\n        mask[start:start + length] = 1\n\n    return mask.reshape(shape, order='C')\n\n\nlogger.info(\"‚úÖ RLE encoding functions (C-order) loaded\")\n\n\n# Cell 5.5: Dice Score Calculation (for per-sample diagnostics)\ndef calculate_dice_score(pred: np.ndarray, gt: np.ndarray) -> float:\n    \"\"\"\n    Calculate Dice coefficient between prediction and ground truth.\n\n    Dice = 2 * |X ‚à© Y| / (|X| + |Y|)\n\n    Args:\n        pred: Binary prediction mask\n        gt: Binary ground truth mask\n\n    Returns:\n        Dice score (0.0 to 1.0). Returns 1.0 if both masks are empty.\n    \"\"\"\n    pred = pred.astype(bool)\n    gt = gt.astype(bool)\n\n    # Handle case where both are empty (perfect score)\n    if pred.sum() == 0 and gt.sum() == 0:\n        return 1.0\n\n    # Handle case where only one is empty\n    if pred.sum() == 0 or gt.sum() == 0:\n        return 0.0\n\n    intersection = np.logical_and(pred, gt).sum()\n    return 2.0 * intersection / (pred.sum() + gt.sum())\n\n\ndef calculate_per_class_dice(pred_masks: Dict[int, np.ndarray], gt_masks: Dict[int, np.ndarray]) -> Dict[int, float]:\n    \"\"\"\n    Calculate Dice scores for each class.\n\n    Args:\n        pred_masks: Dict mapping class (1, 2, 4) to predicted binary mask\n        gt_masks: Dict mapping class (1, 2, 4) to ground truth binary mask\n\n    Returns:\n        Dict mapping class to Dice score\n    \"\"\"\n    dice_scores = {}\n    for cls in [1, 2, 4]:\n        pred = pred_masks.get(cls, np.zeros_like(list(gt_masks.values())[0]))\n        gt = gt_masks.get(cls, np.zeros_like(list(pred_masks.values())[0]))\n        dice_scores[cls] = calculate_dice_score(pred, gt)\n    return dice_scores\n\n\ndef load_ground_truth_masks(patient_folder: str, target_shape: tuple = (240, 240, 155)) -> Dict[int, np.ndarray]:\n    \"\"\"\n    Load ground truth segmentation mask and convert to per-class binary masks.\n\n    The ground truth is loaded in LPS orientation to match the submission format.\n\n    BraTS label convention:\n    - 0: Background\n    - 1: NCR/NET (Necrotic/Non-enhancing Tumor Core)\n    - 2: ED (Peritumoral Edema)\n    - 4: ET (Enhancing Tumor)\n\n    Args:\n        patient_folder: Path to patient folder containing seg.nii.gz\n        target_shape: Expected output shape (should match submission format)\n\n    Returns:\n        Dict mapping class (1, 2, 4) to binary mask in LPS orientation\n    \"\"\"\n    # Find segmentation file\n    seg_path = find_nifti_file(patient_folder, \"seg\")\n    seg_nii = nib.load(seg_path)\n    seg_data = seg_nii.get_fdata().astype(np.uint8)\n\n    # The ground truth is typically in LPS orientation already\n    # But we need to ensure it matches our submission orientation\n    # Load with nibabel and check orientation\n    orig_ornt = nib.orientations.io_orientation(seg_nii.affine)\n    target_ornt = nib.orientations.axcodes2ornt(('L', 'P', 'S'))\n\n    if not np.array_equal(orig_ornt, target_ornt):\n        # Reorient to LPS\n        transform = nib.orientations.ornt_transform(orig_ornt, target_ornt)\n        seg_data = nib.orientations.apply_orientation(seg_data, transform)\n\n    # Resize if needed\n    if seg_data.shape != target_shape:\n        zoom_factors = [t / s for t, s in zip(target_shape, seg_data.shape)]\n        seg_data = zoom(seg_data.astype(np.float32), zoom_factors, order=0).astype(np.uint8)\n        # Ensure exact shape\n        seg_data = seg_data[:target_shape[0], :target_shape[1], :target_shape[2]]\n\n    # Extract per-class masks\n    masks = {\n        1: (seg_data == 1).astype(np.uint8),  # NCR/NET\n        2: (seg_data == 2).astype(np.uint8),  # Edema\n        4: (seg_data == 4).astype(np.uint8),  # Enhancing Tumor\n    }\n\n    return masks\n\n\ndef find_ground_truth_folder(patient_id: str, gt_dir: str) -> str:\n    \"\"\"\n    Find the ground truth folder for a given patient ID.\n\n    Handles potential naming differences between test set and hackathon dataset.\n\n    Args:\n        patient_id: Patient ID from test set (e.g., \"BraTS2021_00000\")\n        gt_dir: Root directory of ground truth dataset\n\n    Returns:\n        Path to ground truth patient folder, or None if not found\n    \"\"\"\n    # Try exact match first\n    exact_path = os.path.join(gt_dir, patient_id)\n    if os.path.isdir(exact_path):\n        return exact_path\n\n    # Try to find by numeric ID\n    try:\n        num_id = patient_id.split(\"_\")[-1]\n        candidates = glob.glob(os.path.join(gt_dir, f\"*{num_id}*\"))\n        folders = [c for c in candidates if os.path.isdir(c)]\n        if folders:\n            return folders[0]\n    except Exception:\n        pass\n\n    return None\n\n\nlogger.info(\"‚úÖ Dice score calculation functions loaded\")\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def find_nifti_file(base_path: str, keyword: str) -> str:\n    \"\"\"Find NIfTI file containing keyword.\"\"\"\n    candidates = glob.glob(os.path.join(base_path, \"**\", f\"*{keyword}*.nii*\"), recursive=True)\n    real_files = [f for f in candidates if os.path.isfile(f)]\n    if not real_files:\n        raise FileNotFoundError(f\"No file found for '{keyword}' in {base_path}\")\n    return max(real_files, key=len)\n\n\ndef get_inference_transforms(config: Config) -> Compose:\n    \"\"\"\n    Inference transforms - uses RAS orientation (like training).\n    Includes CropForeground to match training pipeline.\n    \"\"\"\n    return Compose([\n        LoadImaged(keys=MODALITY_KEYS, image_only=False),\n        EnsureChannelFirstd(keys=MODALITY_KEYS),\n        ConcatItemsd(keys=MODALITY_KEYS, name=\"image\", dim=0),\n        DeleteItemsd(keys=MODALITY_KEYS),\n        Orientationd(keys=[\"image\"], axcodes=\"RAS\"),  # RAS for inference (like training)\n        Spacingd(keys=[\"image\"], pixdim=config.target_spacing, mode=\"bilinear\"),\n        NormalizeIntensityd(keys=[\"image\"], nonzero=True, channel_wise=True),\n        CropForegroundd(keys=[\"image\"], source_key=\"image\"),\n        SpatialPadd(keys=[\"image\"], spatial_size=config.patch_size),\n    ])\n\n\ndef get_pre_crop_transforms() -> Compose:\n    \"\"\"Transforms to get pre-crop shape for coordinate mapping.\"\"\"\n    return Compose([\n        LoadImaged(keys=MODALITY_KEYS, image_only=False),\n        EnsureChannelFirstd(keys=MODALITY_KEYS),\n        ConcatItemsd(keys=MODALITY_KEYS, name=\"image\", dim=0),\n        DeleteItemsd(keys=MODALITY_KEYS),\n        Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n        Spacingd(keys=[\"image\"], pixdim=(1.0, 1.0, 1.0), mode=\"bilinear\"),\n        NormalizeIntensityd(keys=[\"image\"], nonzero=True, channel_wise=True),\n    ])\n\n\ndef get_crop_info_transforms() -> Compose:\n    \"\"\"Transforms to get exact crop shape.\"\"\"\n    return Compose([\n        LoadImaged(keys=MODALITY_KEYS, image_only=False),\n        EnsureChannelFirstd(keys=MODALITY_KEYS),\n        ConcatItemsd(keys=MODALITY_KEYS, name=\"image\", dim=0),\n        DeleteItemsd(keys=MODALITY_KEYS),\n        Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n        Spacingd(keys=[\"image\"], pixdim=(1.0, 1.0, 1.0), mode=\"bilinear\"),\n        NormalizeIntensityd(keys=[\"image\"], nonzero=True, channel_wise=True),\n        CropForegroundd(keys=[\"image\"], source_key=\"image\"),\n    ])\n\n\nlogger.info(\"‚úÖ Transform functions loaded\")\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def post_process_mask(mask: np.ndarray, min_size: int = 100, fill_holes: bool = True,\n                      apply_erosion: bool = False, erosion_iterations: int = 1) -> np.ndarray:\n    \"\"\"\n    Post-process a binary mask:\n    1. Remove small connected components\n    2. Fill holes\n    3. Optional erosion to shrink boundaries\n\n    Args:\n        mask: 3D binary mask\n        min_size: Minimum component size to keep\n        fill_holes: Whether to fill holes in the mask\n        apply_erosion: Whether to apply erosion\n        erosion_iterations: Number of erosion iterations\n\n    Returns:\n        Cleaned mask\n    \"\"\"\n    if mask.sum() == 0:\n        return mask\n\n    cleaned = mask.copy().astype(np.uint8)\n\n    # Remove small components\n    labeled, num_features = scipy_label(cleaned)\n    if num_features > 0:\n        component_sizes = np.bincount(labeled.ravel())\n        component_sizes[0] = 0  # Ignore background\n        large_mask = component_sizes >= min_size\n        cleaned = large_mask[labeled].astype(np.uint8)\n\n    # Fill holes\n    if fill_holes and cleaned.sum() > 0:\n        cleaned = binary_fill_holes(cleaned).astype(np.uint8)\n\n    # Apply erosion to shrink boundaries (reduces false positives)\n    if apply_erosion and cleaned.sum() > 0 and erosion_iterations > 0:\n        cleaned = binary_erosion(cleaned, iterations=erosion_iterations).astype(np.uint8)\n\n    return cleaned\n\n\ndef enforce_tumor_hierarchy(tc: np.ndarray, wt: np.ndarray, et: np.ndarray) -> Tuple[\n    np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Enforce anatomical constraints: ET ‚äÜ TC ‚äÜ WT\n\n    The tumor regions should follow:\n    - Enhancing Tumor (ET) is inside Tumor Core (TC)\n    - Tumor Core (TC) is inside Whole Tumor (WT)\n\n    Args:\n        tc: Tumor Core mask\n        wt: Whole Tumor mask\n        et: Enhancing Tumor mask\n\n    Returns:\n        Corrected (tc, wt, et)\n    \"\"\"\n    # ET must be inside TC\n    et_corrected = (et & tc).astype(np.uint8)\n\n    # TC must be inside WT\n    tc_corrected = (tc & wt).astype(np.uint8)\n\n    # WT stays as is (it's the outermost region)\n    wt_corrected = wt.astype(np.uint8)\n\n    # Final check: ET must be in corrected TC\n    et_corrected = (et_corrected & tc_corrected).astype(np.uint8)\n\n    return tc_corrected, wt_corrected, et_corrected\n\n\ndef keep_largest_component(mask: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Keep only the largest connected component.\n    Useful for removing isolated false positive regions.\n    \"\"\"\n    if mask.sum() == 0:\n        return mask\n\n    labeled, num_features = scipy_label(mask)\n    if num_features <= 1:\n        return mask\n\n    component_sizes = np.bincount(labeled.ravel())\n    component_sizes[0] = 0  # Ignore background\n    largest_label = component_sizes.argmax()\n\n    return (labeled == largest_label).astype(np.uint8)\n\n\nlogger.info(\"‚úÖ Post-processing functions loaded (with erosion support)\")\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def run_inference_with_tta(model, image_tensor: torch.Tensor, inferer,\n                           flip_dims: List[int] = [2, 3, 4]) -> torch.Tensor:\n    \"\"\"\n    Run inference with test-time augmentation (flip augmentations).\n\n    Args:\n        model: PyTorch model\n        image_tensor: Input tensor [B, C, D, H, W]\n        inferer: MONAI SlidingWindowInferer\n        flip_dims: Dimensions to flip (2=D, 3=H, 4=W for 3D)\n\n    Returns:\n        Averaged prediction probabilities\n    \"\"\"\n    model.eval()\n    predictions = []\n\n    with torch.no_grad():\n        # Original\n        with autocast():\n            out = inferer(image_tensor, model)\n            if isinstance(out, tuple):\n                out = out[0]\n            predictions.append(torch.sigmoid(out))\n\n        # Flipped versions\n        for dim in flip_dims:\n            img_flipped = torch.flip(image_tensor, dims=[dim])\n            with autocast():\n                out = inferer(img_flipped, model)\n                if isinstance(out, tuple):\n                    out = out[0]\n                # Flip prediction back\n                pred_flipped = torch.flip(torch.sigmoid(out), dims=[dim])\n                predictions.append(pred_flipped)\n\n    # Average all predictions\n    avg_pred = torch.stack(predictions, dim=0).mean(dim=0)\n    return avg_pred\n\n\nlogger.info(\"‚úÖ TTA function loaded\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def process_single_case(\n        model,\n        patient_folder: str,\n        config: Config,\n        inferer,\n        inference_transforms,\n        pre_crop_transforms,\n        crop_info_transforms,\n        return_masks: bool = False  # [EVAL] Return decoded masks for evaluation\n) -> Dict[int, str]:\n    \"\"\"\n    Process a single patient case and return RLE for each class.\n\n    Args:\n        model: PyTorch model\n        patient_folder: Path to patient folder\n        config: Configuration object\n        inferer: MONAI SlidingWindowInferer\n        inference_transforms: Transform pipeline\n        pre_crop_transforms: Pre-crop transform pipeline\n        crop_info_transforms: Crop info transform pipeline\n        return_masks: If True, also return decoded masks for evaluation\n\n    Returns:\n        If return_masks=False: Dict mapping class (1, 2, 4) to RLE string\n        If return_masks=True: Tuple of (RLE dict, masks dict) where masks dict\n                              maps class (1, 2, 4) to binary numpy arrays\n    \"\"\"\n    patient_id = os.path.basename(patient_folder)\n\n    # Load original file for shape info\n    flair_path = find_nifti_file(patient_folder, \"flair\")\n    original_nii = nib.load(flair_path)\n    original_shape = original_nii.shape  # (240, 240, 155)\n\n    # Create data dict\n    data = {k: find_nifti_file(patient_folder, k) for k in MODALITY_KEYS}\n\n    # Get pre-crop info (RAS space before crop)\n    pre_data = pre_crop_transforms(dict(data))\n    pre_img = pre_data[\"image\"].numpy()\n    pre_shape = list(pre_img.shape[1:])\n\n    # Find crop box (where non-zero voxels are)\n    nz = np.where(np.any(pre_img != 0, axis=0))\n    crop_start = [int(nz[i].min()) for i in range(3)]\n\n    # Get actual cropped shape\n    crop_data = crop_info_transforms({k: find_nifti_file(patient_folder, k) for k in MODALITY_KEYS})\n    actual_crop_shape = list(crop_data[\"image\"].shape[1:])\n    crop_end = [crop_start[i] + actual_crop_shape[i] for i in range(3)]\n\n    # Full inference transform (includes padding)\n    full_data = inference_transforms({k: find_nifti_file(patient_folder, k) for k in MODALITY_KEYS})\n    img = full_data[\"image\"]\n\n    # Calculate pad offsets\n    pad_offset = [(config.patch_size[i] - actual_crop_shape[i]) // 2\n                  if actual_crop_shape[i] < config.patch_size[i] else 0\n                  for i in range(3)]\n\n    # Run inference\n    x = img.unsqueeze(0).to(device)\n\n    if config.use_tta:\n        pred_probs = run_inference_with_tta(model, x, inferer, flip_dims=[2, 3, 4])\n    else:\n        with torch.no_grad():\n            with autocast():\n                out = inferer(x, model)\n                if isinstance(out, tuple):\n                    out = out[0]\n                pred_probs = torch.sigmoid(out)\n\n    pred_probs = pred_probs.cpu().numpy()[0]  # [3, D, H, W]\n\n    # Apply per-class thresholds\n    tc = (pred_probs[0] > config.threshold_tc).astype(np.uint8)  # Channel 0 = TC\n    wt = (pred_probs[1] > config.threshold_wt).astype(np.uint8)  # Channel 1 = WT\n    et = (pred_probs[2] > config.threshold_et).astype(np.uint8)  # Channel 2 = ET\n\n    # Unpad (remove padding added by SpatialPadd)\n    o = pad_offset\n    s = actual_crop_shape\n    tc_crop = tc[o[0]:o[0] + s[0], o[1]:o[1] + s[1], o[2]:o[2] + s[2]]\n    wt_crop = wt[o[0]:o[0] + s[0], o[1]:o[1] + s[1], o[2]:o[2] + s[2]]\n    et_crop = et[o[0]:o[0] + s[0], o[1]:o[1] + s[1], o[2]:o[2] + s[2]]\n\n    # Place back into full RAS volume\n    tc_ras = np.zeros(pre_shape, dtype=np.uint8)\n    wt_ras = np.zeros(pre_shape, dtype=np.uint8)\n    et_ras = np.zeros(pre_shape, dtype=np.uint8)\n\n    c, e = crop_start, crop_end\n    tc_ras[c[0]:e[0], c[1]:e[1], c[2]:e[2]] = tc_crop\n    wt_ras[c[0]:e[0], c[1]:e[1], c[2]:e[2]] = wt_crop\n    et_ras[c[0]:e[0], c[1]:e[1], c[2]:e[2]] = et_crop\n\n    # Enforce hierarchy FIRST (before post-processing)\n    if config.enforce_hierarchy:\n        tc_ras, wt_ras, et_ras = enforce_tumor_hierarchy(tc_ras, wt_ras, et_ras)\n\n    # Post-process each mask (now with erosion option)\n    tc_ras = post_process_mask(tc_ras, config.min_component_size, config.fill_holes,\n                               config.apply_erosion, config.erosion_iterations)\n    wt_ras = post_process_mask(wt_ras, config.min_component_size, config.fill_holes,\n                               config.apply_erosion, config.erosion_iterations)\n    et_ras = post_process_mask(et_ras, config.min_component_size, config.fill_holes,\n                               config.apply_erosion, config.erosion_iterations)\n\n    # Re-enforce hierarchy AFTER post-processing (erosion can break hierarchy)\n    if config.enforce_hierarchy:\n        tc_ras, wt_ras, et_ras = enforce_tumor_hierarchy(tc_ras, wt_ras, et_ras)\n\n    # RAS ‚Üí LPS conversion (flip X and Y axes)\n    tc_lps = np.flip(np.flip(tc_ras, 0), 1).copy()\n    wt_lps = np.flip(np.flip(wt_ras, 0), 1).copy()\n    et_lps = np.flip(np.flip(et_ras, 0), 1).copy()\n\n    # Resample to original shape if needed (spacing might differ)\n    if tc_lps.shape != original_shape:\n        zoom_factors = [o / c for o, c in zip(original_shape, tc_lps.shape)]\n        tc_lps = zoom(tc_lps.astype(np.float32), zoom_factors, order=0).astype(np.uint8)\n        wt_lps = zoom(wt_lps.astype(np.float32), zoom_factors, order=0).astype(np.uint8)\n        et_lps = zoom(et_lps.astype(np.float32), zoom_factors, order=0).astype(np.uint8)\n\n        # Ensure exact shape\n        tc_lps = tc_lps[:original_shape[0], :original_shape[1], :original_shape[2]]\n        wt_lps = wt_lps[:original_shape[0], :original_shape[1], :original_shape[2]]\n        et_lps = et_lps[:original_shape[0], :original_shape[1], :original_shape[2]]\n\n    # Derive BraTS submission classes:\n    # Class 1 (NCR/NET): TC - ET (Necrotic/Non-enhancing tumor core)\n    # Class 2 (ED): WT - TC (Peritumoral edema)\n    # Class 4 (ET): ET directly (Enhancing tumor)\n    class_1 = ((tc_lps > 0) & (et_lps == 0)).astype(np.uint8)  # NCR/NET = TC - ET\n    class_2 = ((wt_lps > 0) & (tc_lps == 0)).astype(np.uint8)  # Edema = WT - TC\n    class_4 = et_lps.astype(np.uint8)  # ET directly\n\n    # [DIAGNOSTIC LOGGING] Log final voxel counts after RAS‚ÜíLPS conversion and resampling\n    logger.info(f\"  Final voxel counts: Class1={class_1.sum():,}, Class2={class_2.sum():,}, Class4={class_4.sum():,}\")\n    sys.stdout.flush()\n\n    # Generate RLE (C-order)\n    rle_1 = rle_encode_c_order(class_1)\n    rle_2 = rle_encode_c_order(class_2)\n    rle_4 = rle_encode_c_order(class_4)\n\n    rle_dict = {1: rle_1, 2: rle_2, 4: rle_4}\n\n    if return_masks:\n        # Return both RLE and decoded masks for evaluation\n        masks_dict = {1: class_1, 2: class_2, 4: class_4}\n        return rle_dict, masks_dict\n\n    return rle_dict\n\n\nlogger.info(\"‚úÖ Main processing pipeline loaded (with enhanced post-processing)\")\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_submission(config: Config, target_id: str = None) -> pd.DataFrame:\n    \"\"\"\n    Generate submission CSV for all test cases.\n    [EVAL] Optional Dice score evaluation when ground truth is available.\n\n    Returns:\n        Tuple of (submission_df, stats_df, eval_df) where eval_df is None if evaluation disabled\n    \"\"\"\n    # Setup inferer\n    inferer = SlidingWindowInferer(\n        roi_size=config.patch_size,\n        sw_batch_size=config.sw_batch_size,\n        overlap=config.overlap,\n        mode=\"gaussian\"\n    )\n\n    # Setup transforms\n    inference_transforms = get_inference_transforms(config)\n    pre_crop_transforms = get_pre_crop_transforms()\n    crop_info_transforms = get_crop_info_transforms()\n\n    # Find all test cases\n    test_folders = sorted(glob.glob(os.path.join(config.test_dir, \"BraTS*\")))\n\n    # Filter for specific case if requested\n    if target_id:\n        test_folders = [f for f in test_folders if target_id in os.path.basename(f)]\n        logger.info(f\"üîç DEBUG MODE: Processing ONLY case '{target_id}'\")\n\n    logger.info(f\"Found {len(test_folders)} test cases\")\n    logger.info(\n        f\"Settings: TTA={config.use_tta}, Thresholds=[{config.threshold_tc}, {config.threshold_wt}, {config.threshold_et}]\")\n    sys.stdout.flush()\n\n    # [EVAL] Check if evaluation is enabled and ground truth is available\n    evaluation_enabled = config.enable_evaluation and os.path.isdir(config.ground_truth_dir)\n    if config.enable_evaluation:\n        if evaluation_enabled:\n            logger.info(f\"[EVAL] ‚úÖ Evaluation ENABLED - Ground truth dir: {config.ground_truth_dir}\")\n        else:\n            logger.warning(f\"[EVAL] ‚ö†Ô∏è Evaluation requested but ground truth dir not found: {config.ground_truth_dir}\")\n            evaluation_enabled = False\n    sys.stdout.flush()\n\n    all_rows = []\n    stats = []\n    eval_results = []  # [EVAL] Store per-case Dice scores\n\n    # [EVAL] Track best and worst cases\n    best_case = {\"patient\": None, \"mean_dice\": -1}\n    worst_case = {\"patient\": None, \"mean_dice\": 2}\n\n    logger.info(\"=\" * 70)\n    logger.info(\"STARTING INFERENCE ON TEST CASES\")\n    logger.info(\"=\" * 70)\n    sys.stdout.flush()\n\n    total_cases = len(test_folders)\n    for idx, patient_folder in enumerate(test_folders, 1):\n        patient_id = os.path.basename(patient_folder)\n        case_start_time = time.time()\n\n        logger.info(f\"Processing case {idx}/{total_cases}: {patient_id}\")\n        sys.stdout.flush()\n\n        try:\n            # [EVAL] Request masks if evaluation is enabled\n            result = process_single_case(\n                model=model,\n                patient_folder=patient_folder,\n                config=config,\n                inferer=inferer,\n                inference_transforms=inference_transforms,\n                pre_crop_transforms=pre_crop_transforms,\n                crop_info_transforms=crop_info_transforms,\n                return_masks=evaluation_enabled\n            )\n\n            if evaluation_enabled:\n                rle_dict, pred_masks = result\n            else:\n                rle_dict = result\n                pred_masks = None\n\n            # Count voxels for stats\n            voxel_counts = {}\n            for cls, rle in rle_dict.items():\n                if pred_masks is not None:\n                    # Use already-decoded masks\n                    voxel_counts[f\"c{cls}\"] = int(pred_masks[cls].sum())\n                else:\n                    mask = rle_decode_c_order(rle, ORIGINAL_SHAPE)\n                    voxel_counts[f\"c{cls}\"] = int(mask.sum())\n                all_rows.append({\"id\": f\"{patient_id}_{cls}\", \"rle\": rle if rle else \"\"})\n\n            stats.append({\"patient\": patient_id, **voxel_counts})\n\n            # Log processing time\n            case_time = time.time() - case_start_time\n            logger.info(f\"  ‚úì Completed in {case_time:.2f}s\")\n            sys.stdout.flush()\n\n            # [EVAL] Calculate Dice scores if evaluation is enabled\n            if evaluation_enabled:\n                gt_folder = find_ground_truth_folder(patient_id, config.ground_truth_dir)\n                if gt_folder:\n                    try:\n                        gt_masks = load_ground_truth_masks(gt_folder, ORIGINAL_SHAPE)\n                        dice_scores = calculate_per_class_dice(pred_masks, gt_masks)\n                        mean_dice = np.mean(list(dice_scores.values()))\n\n                        eval_results.append({\n                            \"patient\": patient_id,\n                            \"dice_class1\": dice_scores[1],\n                            \"dice_class2\": dice_scores[2],\n                            \"dice_class4\": dice_scores[4],\n                            \"mean_dice\": mean_dice\n                        })\n\n                        # Track best and worst\n                        if mean_dice > best_case[\"mean_dice\"]:\n                            best_case = {\"patient\": patient_id, \"mean_dice\": mean_dice}\n                        if mean_dice < worst_case[\"mean_dice\"]:\n                            worst_case = {\"patient\": patient_id, \"mean_dice\": mean_dice}\n\n                        # Log per-case Dice score\n                        logger.info(f\"  [EVAL] Dice Scores: Class1={dice_scores[1]:.4f}, Class2={dice_scores[2]:.4f}, Class4={dice_scores[4]:.4f}, Mean={mean_dice:.4f}\")\n                        sys.stdout.flush()\n\n                    except Exception as eval_ex:\n                        logger.warning(f\"  [EVAL ERROR] {eval_ex}\")\n                        sys.stdout.flush()\n                        eval_results.append({\n                            \"patient\": patient_id,\n                            \"dice_class1\": np.nan,\n                            \"dice_class2\": np.nan,\n                            \"dice_class4\": np.nan,\n                            \"mean_dice\": np.nan\n                        })\n                else:\n                    logger.warning(f\"  [EVAL] Ground truth not found\")\n                    sys.stdout.flush()\n                    eval_results.append({\n                        \"patient\": patient_id,\n                        \"dice_class1\": np.nan,\n                        \"dice_class2\": np.nan,\n                        \"dice_class4\": np.nan,\n                        \"mean_dice\": np.nan\n                    })\n\n        except Exception as ex:\n            logger.error(f\"  ‚ùå Error processing {patient_id}: {ex}\")\n            sys.stdout.flush()\n            for cls in [1, 2, 4]:\n                all_rows.append({\"id\": f\"{patient_id}_{cls}\", \"rle\": \"\"})\n            stats.append({\"patient\": patient_id, \"c1\": 0, \"c2\": 0, \"c4\": 0})\n            if evaluation_enabled:\n                eval_results.append({\n                    \"patient\": patient_id,\n                    \"dice_class1\": np.nan,\n                    \"dice_class2\": np.nan,\n                    \"dice_class4\": np.nan,\n                    \"mean_dice\": np.nan\n                })\n\n    # Create and save submission\n    logger.info(\"=\" * 70)\n    logger.info(\"SAVING SUBMISSION\")\n    logger.info(\"=\" * 70)\n    submission_df = pd.DataFrame(all_rows).sort_values(\"id\").reset_index(drop=True)\n    submission_df.to_csv(config.output_csv, index=False)\n\n    logger.info(f\"‚úÖ Submission saved to: {config.output_csv}\")\n    logger.info(f\"Total rows: {len(submission_df)}\")\n    sys.stdout.flush()\n\n    # Print statistics\n    stats_df = pd.DataFrame(stats)\n    logger.info(\"\")\n    logger.info(\"üìä Prediction Statistics:\")\n    logger.info(\n        f\"  Cases with tumor (any class > 0): {((stats_df['c1'] > 0) | (stats_df['c2'] > 0) | (stats_df['c4'] > 0)).sum()}/{len(stats_df)}\")\n    logger.info(f\"  Mean Class 1 (NCR/NET) voxels: {stats_df['c1'].mean():.0f}\")\n    logger.info(f\"  Mean Class 2 (Edema) voxels:   {stats_df['c2'].mean():.0f}\")\n    logger.info(f\"  Mean Class 4 (ET) voxels:      {stats_df['c4'].mean():.0f}\")\n    sys.stdout.flush()\n\n    # [EVAL] Print evaluation summary\n    eval_df = None\n    if evaluation_enabled and eval_results:\n        eval_df = pd.DataFrame(eval_results)\n        valid_evals = eval_df.dropna()\n\n        logger.info(\"\")\n        logger.info(\"=\" * 70)\n        logger.info(\"üìä EVALUATION RESULTS (Dice Scores)\")\n        logger.info(\"=\" * 70)\n        logger.info(f\"  Cases evaluated: {len(valid_evals)}/{len(eval_results)}\")\n\n        if len(valid_evals) > 0:\n            logger.info(\"\")\n            logger.info(\"  üìà MEAN DICE SCORES:\")\n            logger.info(f\"     Class 1 (NCR/NET):     {valid_evals['dice_class1'].mean():.4f}\")\n            logger.info(f\"     Class 2 (Edema):       {valid_evals['dice_class2'].mean():.4f}\")\n            logger.info(f\"     Class 4 (ET):          {valid_evals['dice_class4'].mean():.4f}\")\n            logger.info(f\"     ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\")\n            logger.info(f\"     OVERALL MEAN DICE:     {valid_evals['mean_dice'].mean():.4f}\")\n\n            logger.info(\"\")\n            logger.info(f\"  üèÜ BEST CASE:  {best_case['patient']} (Mean Dice: {best_case['mean_dice']:.4f})\")\n            logger.info(f\"  ‚ö†Ô∏è  WORST CASE: {worst_case['patient']} (Mean Dice: {worst_case['mean_dice']:.4f})\")\n\n            # Per-class statistics\n            logger.info(\"\")\n            logger.info(\"  üìä PER-CLASS STATISTICS:\")\n            for cls, col in [(1, 'dice_class1'), (2, 'dice_class2'), (4, 'dice_class4')]:\n                cls_data = valid_evals[col]\n                logger.info(f\"     Class {cls}: Mean={cls_data.mean():.4f}, Std={cls_data.std():.4f}, \"\n                      f\"Min={cls_data.min():.4f}, Max={cls_data.max():.4f}\")\n\n        logger.info(\"=\" * 70)\n\n        # Save evaluation results\n        eval_csv_path = config.output_csv.replace('.csv', '_evaluation.csv')\n        eval_df.to_csv(eval_csv_path, index=False)\n        logger.info(f\"  Evaluation results saved to: {eval_csv_path}\")\n        sys.stdout.flush()\n\n    return submission_df, stats_df, eval_df","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 11: Run Full Submission Generation\nlogger.info(\"=\" * 70)\nlogger.info(\"GENERATING FINAL SUBMISSION (ALL TEST CASES)\")\nlogger.info(\"=\" * 70)\nlogger.info(\"\")\nlogger.info(\"Pipeline Settings:\")\nlogger.info(f\"  ‚úÖ C-order RLE encoding (correct format)\")\nlogger.info(f\"  ‚úÖ RAS ‚Üí LPS orientation conversion\")\nlogger.info(f\"  ‚úÖ Per-class thresholds: TC={config.threshold_tc}, WT={config.threshold_wt}, ET={config.threshold_et}\")\nlogger.info(f\"  ‚úÖ Post-processing: min_size={config.min_component_size}, fill_holes={config.fill_holes}\")\nlogger.info(f\"  ‚úÖ Tumor hierarchy enforcement: {config.enforce_hierarchy}\")\nlogger.info(f\"  ‚úÖ Test-Time Augmentation: {config.use_tta}\")\nlogger.info(f\"  ‚úÖ Overlap: {config.overlap}\")\nlogger.info(f\"  ‚úÖ Evaluation: {config.enable_evaluation}\")\nlogger.info(\"\")\nsys.stdout.flush()\n\n# Generate submission for ALL test cases\nsubmission_df, stats_df, eval_df = generate_submission(config)\n\n# Preview\nlogger.info(\"\")\nlogger.info(\"üìã Submission Preview (first 15 rows):\")\nlogger.info(\"\\n\" + submission_df.head(15).to_string(index=False))\nlogger.info(\"\")\nlogger.info(\"=\" * 70)\nlogger.info(\"‚úÖ SUBMISSION GENERATION COMPLETE\")\nlogger.info(\"=\" * 70)\nsys.stdout.flush()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ‚úÖ Submission Complete\n\nYour submission file has been saved to: `/kaggle/working/submission.csv`\n\n### Pipeline Summary\n| Component | Setting |\n|-----------|---------|\n| RLE Encoding | C-order (row-major), 1-indexed |\n| Orientation | RAS inference ‚Üí LPS submission |\n| Thresholds | TC=0.52, WT=0.47, ET=0.57 |\n| Post-processing | min_size=150, fill_holes=True |\n| Hierarchy | ET ‚äÜ TC ‚äÜ WT enforced |\n| TTA | Flip augmentation (X, Y, Z) |\n| Overlap | 0.6 |\n\n### Download and Submit\nRun this to download:\n```python\nfrom IPython.display import FileLink\nFileLink('submission.csv')\n```","metadata":{}}]}